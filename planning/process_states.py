import json
import random
from typing import Union, List

from GPT_Agents import *


INIT_STATE = [
    "(robot-at rob l0)",
    "(robot-at support0 l0)",
    "(support support0)",
    "(grape-at g0 l0)",
    "(grape-at g1 l1)",
    "(grape-at g2 l2)",
    "(grape-at g3 l3)",
    "(unchecked l0)",
    "(unchecked l1)",
    "(unchecked l2)",
    "(unchecked l3)",
    "(free rob)",
    "(in b rob)",
    "(adj l0 l1)",
    "(adj l1 l2)",
    "(adj l2 l3)",
    "(full b)",
]

PLAN_PATH = "config/PDDL/sas_plan_adapted"

domain = []
DOMAIN_PATH = "config/PDDL/domain.pddl"
with open(DOMAIN_PATH, "r") as file:
    domain = file.read()

problem = []
PROBLEM_PATH = "config/PDDL/problem.pddl"
with open(PROBLEM_PATH, "r") as file:
    problem = file.read()

human_policy = []
POLICY_PATH = "config/PDDL/human_policy.pol"
with open(POLICY_PATH, "r") as file:
    human_policy = file.read()

chat_kwargs = {"domain": domain, "problem": problem, "human_policy": human_policy}

with open("config/action_schemas.json", "r") as file:
    ACTIONS_SCHEMA = json.load(file)


def process_action(action):
    # split name and arguments
    action = action.replace("(", "").replace(")", "")
    action = action.split(" ")
    action = {
        "name": action[0],
        "args": action[1:],
    }

    # print("ACTION ", action)

    action_schema = ACTIONS_SCHEMA[action["name"]]
    add_set = action_schema["add_set"].split(",")
    del_set = action_schema["del_set"].split(",")
    for i, arg in enumerate(action["args"]):
        add_set = [x.replace(f"?{i+1}", arg) for x in add_set]
        del_set = [x.replace(f"?{i+1}", arg) for x in del_set]

    return action, set(add_set), set(del_set)


def add_fluents(state, add_set):
    for fluent in add_set:
        if fluent not in state:
            state.add(fluent)
    return state


def remove_fluents(state, del_set):
    for fluent in del_set:
        if fluent in state:
            state.remove(fluent)
    return state


def get_next_state(state, action):
    action, add_set, del_set = process_action(action)

    state=add_fluents(state, add_set)
    state=remove_fluents(state, del_set)

    return state


def get_current_state(plan_so_far):
    state = INIT_STATE.copy()
    state = set(state)

    for action in plan_so_far:
        state=get_next_state(state, action)

    return set(state)


def get_future_states(plan_so_far, plan):
    state = INIT_STATE.copy()
    state = set(state)

    for action in plan_so_far:
        get_next_state(state, action)

    states = [state]
    last_action = plan_so_far[-1]
    last_action_index = plan.index(last_action)

    for action in plan[last_action_index + 1 :]:
        get_next_state(state, action)
        states.append(state)

    return set(states)


def get_past_states(plan_so_far):
    state = INIT_STATE.copy()
    state = set(state)

    states = [state]
    for action in plan_so_far:
        get_next_state(state, action)
        states.append(state)

    return set(states)


def evaluate_metric(
    plan_so_far_returned, extracted_fluents, category
):
    if category == "Current_action":
        #Equation 1 in the paper
        real_states = get_current_state(plan_so_far_returned)
        intersection = real_states & extracted_fluents
        union = real_states | extracted_fluents
        gamma_present = len(intersection) / len(union) 
        return gamma_present

    elif category == "Past_actions":
        #Equation 2 in the paper
        cumulative_plan = []
        gamma_past = 0.0
        t = 0
        for action in plan_so_far_returned:
            cumulative_plan.append(action)
            real_states = get_current_state(cumulative_plan)
            intersection = real_states & extracted_fluents
            union = real_states | extracted_fluents
            gamma_past += len(intersection) / len(union)
            t+=1
        gamma_past = gamma_past / t
        return gamma_past
    
    elif category == "Future_actions":
        #Equation 3 in the paper
        gt_plan = load_plan(PLAN_PATH)
        T = len(gt_plan)
        t = len(plan_so_far_returned)
        cumulative_plan = plan_so_far_returned.copy()
        gamma_future = 0.0
        i = 0
        for action in gt_plan[t:]:
            real_states = get_current_state(cumulative_plan)
            intersection = real_states & extracted_fluents
            union = real_states | extracted_fluents
            gamma_future += len(intersection) / len(union)
            cumulative_plan.append(action)
            i+=1
        gamma_future = gamma_future / i
        return gamma_future
    else:
        raise ValueError("Invalid category")

def simulate_plan(plan, question, question_probability=0.25):
    p = question_probability
    increment = (1 - p) / len(plan)
    plan_so_far = []
    psf_returned = []
    system_response = []
    for i, action in enumerate(plan):
        plan_so_far.append(f"{i+1}) {action}")
        psf_returned.append(action)

        if random.random() < p:
            user_response = question
            chat = GPTChat(**chat_kwargs)
            system_response = chat(plan_so_far, user_response)
            break
        else:
            p += increment
            p = min(1, p)

    return system_response, psf_returned


def load_plan(plan_path):
    plan = []
    with open(plan_path, "r") as file:
        temp = file.readlines()
        plan.extend(line.replace("\n", "") for line in temp)
    return plan
